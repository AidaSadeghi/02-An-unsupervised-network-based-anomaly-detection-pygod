{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d63c2b2-8d28-4142-9821-66efd29bc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os, sys\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "from networkx import pagerank\n",
    "from networkx import set_node_attributes\n",
    "\n",
    "from torch_geometric.data import Data \n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196e25e1-f266-4e6d-85f6-32b37d6ecc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987082a2-2409-4c7e-9c6d-6e18ba799bde",
   "metadata": {},
   "outputs": [],
   "source": [
    " !nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e55dc85-6568-4232-8457-5088e9f6b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ccf.csv\",sep=';')\n",
    "\n",
    "# df = df.drop(['TX_DATETIME'], axis=1)\n",
    "df = df.drop(['TERM_COUNTRY'], axis=1)\n",
    "df.head(5)\n",
    "\n",
    "df['TX_FRAUD'] = df['TX_FRAUD'].astype(int)\n",
    "df['TX_ACCEPTED'] = df['TX_ACCEPTED'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400aecd7-a1ae-4760-ab58-8afc6de84957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538e7a1-3c68-4d0d-93e1-d0167121c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7786b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c1ee5a-c8e3-4a2b-8126-9afb5fdd022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df = df.drop(['TX_DATETIME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32312dca-69af-4f37-bd85-407079ae564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23d4840-41cf-45bc-890e-5ea8219cd1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3724348, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c3f640-dc14-433c-b97d-237c4161a1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TX_FRAUD\n",
       "0    3700000\n",
       "1      24348\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TX_FRAUD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3471e8ba-479a-477e-ab1c-07d224b04f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CARD_PAN_ID    0\n",
       "TERM_MIDUID    0\n",
       "TERM_MCC       0\n",
       "TX_AMOUNT      0\n",
       "TX_ACCEPTED    0\n",
       "TX_FRAUD       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81be212-550d-4828-95f3-95e397b7b392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CARD_PAN_ID', 'TERM_MIDUID', 'TERM_MCC', 'TX_AMOUNT', 'TX_ACCEPTED',\n",
       "       'TX_FRAUD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73d7b2-e4ac-4b00-a24a-af82fea2f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing info on the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfae11-82f0-487e-aa32-d7b5e1c9641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667535a-0d2c-4b60-8286-ef68e16152a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TX_AMOUNT'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b095f2-d5d6-45e9-98bd-5b6a6d29308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df is your DataFrame and 'TX_AMOUNT' is the column you want to convert to float\n",
    "# Remove commas from 'TX_AMOUNT' column and convert to float\n",
    "df['TX_AMOUNT'] = df['TX_AMOUNT'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5e1ae-54b7-4c7d-abb8-aaee30a77dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Initialize label encoders\n",
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder2 = LabelEncoder()\n",
    "\n",
    "# Encode the columns\n",
    "df['CARD_PAN_ID'] = label_encoder1.fit_transform(df['CARD_PAN_ID'])\n",
    "df['TERM_MIDUID'] = label_encoder2.fit_transform(df['TERM_MIDUID'])\n",
    "\n",
    "# Ensure uniqueness\n",
    "df['CARD_PAN_ID'] = df['CARD_PAN_ID'] + max(df['TERM_MIDUID']) + 1\n",
    "\n",
    "# Display the DataFrame with encoded columns\n",
    "print(df.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590e4b36-579e-4140-9a00-78d5a9d65380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('new_IDs_ccf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b58ab-f8a7-4f85-97de-f607eabf1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing info on the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ed4e4b0-4b92-410f-8ece-9a7b949538d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(df['CARD_PAN_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcf996-cc64-46b4-8ddd-9b69b9e36dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CARD_PAN_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd82b5-89a0-4289-9e28-ba0436684648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TERM_MIDUID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5d8cc-605f-4b73-a913-c4b9960e290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdfeb1-4868-4d21-b234-78e669569707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb2f415-d2aa-4aad-a75b-14ba85af4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Specify the columns you want to scale\n",
    "columns_to_scale = ['TERM_MCC']  # Replace with the actual column names\n",
    "\n",
    "# Fit the scaler to your data\n",
    "scaler.fit(df[columns_to_scale])\n",
    "\n",
    "# Transform the data using the fitted scaler\n",
    "scaled_data = scaler.transform(df[columns_to_scale])\n",
    "\n",
    "# Replace the original columns with the scaled data\n",
    "df[columns_to_scale] = scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f01ed1-f89f-45d3-9256-6377a6afbb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a98430-730d-4758-93a0-610ad3ca849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "# Store heatmap object in a variable to easily access it when you want to include more features (such as title).\n",
    "# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.\n",
    "heatmap = sns.heatmap(correlation_matrix, vmin=-1, vmax=1, annot=True)\n",
    "# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbbdda-8e0b-44cd-a307-f645d88c0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df[df.columns], figsize=(30, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40646312-d00d-4453-9880-d538cf645b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CARD_PAN_ID', 'TERM_MIDUID', 'TERM_MCC', 'TX_AMOUNT', 'TX_ACCEPTED',\n",
       "       'TX_FRAUD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "682030e2-470f-462e-9b66-741127498100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CARD_PAN_ID', 'TERM_MIDUID', 'TERM_MCC', 'TX_AMOUNT', 'TX_ACCEPTED', 'TX_FRAUD']\n"
     ]
    }
   ],
   "source": [
    "attribute_cols = list(df.columns)\n",
    "print(attribute_cols)\n",
    "attribute_cols.remove('CARD_PAN_ID')\n",
    "# attribute_cols.remove('AGENT_NAME')\n",
    "attribute_cols.remove('TERM_MIDUID')\n",
    "attribute_cols.remove('TX_FRAUD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0c0e8b-bb47-4dc8-8ad8-fe5ff0ca5c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TERM_MCC', 'TX_AMOUNT', 'TX_ACCEPTED']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9653101-f137-4e74-9a00-07888a7d2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import circular_layout, spectral_layout\n",
    "\n",
    "def make_graph(df):\n",
    "    G = nx.Graph()\n",
    "    # nx.set_edge_attributes(G_to_draw, labels, \"labels\")\n",
    "    for index, row in df.iterrows():\n",
    "        set_node_attributes(G, row[attribute_cols].values, name=row['TERM_MIDUID'])\n",
    "        G.add_edge(row['CARD_PAN_ID'], row['TERM_MIDUID'])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a76e89ac-6f26-4dbd-b5be-ba7fa3325f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, we are creating a small network with 20 rows so that we can draw it\n",
    "G_to_draw = nx.Graph()\n",
    "for index, row in df.head(90).iterrows():\n",
    "    # G_to_draw.add_edge(row['ID'], row['AGENT_NAME'])\n",
    "    G_to_draw.add_edge(row['CARD_PAN_ID'], row['TERM_MIDUID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2378056-9a84-464e-9749-59a8cb7118ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(G_to_draw, \n",
    "        node_size=1000, \n",
    "        with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98cda3-3676-452b-8a92-305832765427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602f05e-7b4e-45da-b763-6ebe44e7f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df =  make_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cc27f-b471-42f2-92b0-2002b2fc05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pagerank(graph_df, alpha=0.85, personalization=None, max_iter=100, tol=1e-06, nstart=None, dangling=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc0ddd-aa93-4ffc-a69c-4231986204f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['pagerank_TERM_MCC'] = df['TERM_MCC'].apply(lambda x: pr[x])\n",
    "#df['pagerank_TX_AMOUNT'] = df['TX_AMOUNT'].apply(lambda x: pr[x])\n",
    "#df['pagerank_TX_ACCEPTED'] = df['TX_ACCEPTED'].apply(lambda x: pr[x])\n",
    "df['pagerank_CARD_PAN_ID'] = df['CARD_PAN_ID'].apply(lambda x: pr[x])\n",
    "df['pagerank_TERM_MIDUID'] = df['TERM_MIDUID'].apply(lambda x: pr[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4439d16-1af7-43d6-8800-9f360cda06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4719148d-8ebc-4bd7-a98d-f0c2c6087ea2",
   "metadata": {},
   "source": [
    "other network features to use:\n",
    "1- bayan (best community detection out there)\n",
    "https://colab.research.google.com/drive/1_Clxp5FcEYJVn_w7Q6zm8bX0t1TEg7m_?usp=sharing\n",
    "2- reconstruction of a network: (work of tiago in NetSci)\n",
    "https://graph-tool.skewed.de/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318394d8-02f8-47eb-9f30-6e6e80d4acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_embeddings(graph):\n",
    "    # extracting network measures to use as node attributes\n",
    "    #degree=np.array(list(dict(graph.degree()).values())).reshape(-1,1) \n",
    "    #degree_centrality=np.array(list(dict(nx.degree_centrality(graph)).values())).reshape(-1,1)\n",
    "    #closeness=np.array(list(dict(nx.closeness_centrality(graph)).values())).reshape(-1,1)\n",
    "    #betweenness=np.array(list(dict(nx.betweenness_centrality(graph)).values())).reshape(-1,1)\n",
    "    #clustering_coefficient=np.array(list(dict(nx.clustering(graph)).values())).reshape(-1,1)\n",
    "    #pagerank = ncp.array(list(dict(nx.pagerank(graph)).values())).reshape(-1,1)\n",
    "    #personalised_pagerank=np.array(list(dict(nx.pagerank(graph, personalization=nx.get_node_attributes(graph, 'fraud'))).values())).reshape(-1,1)\n",
    "    #embeddings = np.concatenate((degree, closeness, betweenness,distance_instructor, distance_admin),axis=1)\n",
    "   \n",
    "    #embeddings = np.concatenate((degree, closeness, betweenness),axis=1)\n",
    "    #embeddings = np.concatenate((degree_centrality, clustering_coefficient, pagerank),axis=1)\n",
    "    # normalizing the attributes\n",
    "    #scale = StandardScaler()\n",
    "    #embeddings = scale.fit_transform(embeddings)#.reshape(-1,1))\n",
    "    #return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4fd58-11f0-4d3e-89d4-1d662b20363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = nx.degree_centrality(G_full)\n",
    "\n",
    "df['degree_centrality_id'] = df['ID'].apply(lambda x: dc[x])\n",
    "df['degree_centrality_agent_name'] = df['AGENT_NAME'].apply(lambda x: dc[x])\n",
    "df['degree_centrality_supervisor_issue'] = df['SUPERVISOR_ISSUE'].apply(lambda x: dc[x])\n",
    "df['degree_centrality_place_issue'] = df['PLACE_ISSUED'].apply(lambda x: dc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7afa6-2008-4061-8348-9aa5a37eb3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['TX_FRAUD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "628608ca-fa9e-41ca-a1ab-c66132ccb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['CARD_PAN_ID'] = label_encoder.fit_transform(df['CARD_PAN_ID'])\n",
    "df['TERM_MIDUID'] = label_encoder.fit_transform(df['TERM_MIDUID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29cf70",
   "metadata": {},
   "source": [
    "Splitting now the df into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(df):\n",
    "    # Assuming you have a DataFrame named df with a 'date' column\n",
    "\n",
    "    # Convert the 'date' column to a datetime data type\n",
    "    df['date'] = pd.to_datetime(df['TX_DATETIME'])\n",
    "\n",
    "    # Define the date ranges for train, validation, and test\n",
    "    # train_start = pd.to_datetime('2013-10-01')\n",
    "    # train_end = pd.to_datetime('2013-10-25')\n",
    "    # test_end = pd.to_datetime('2013-11-06')\n",
    "\n",
    "    train_start = pd.to_datetime('2013-10-01')\n",
    "    train_end = pd.to_datetime('2013-10-03')\n",
    "    test_end = pd.to_datetime('2013-10-04')\n",
    "\n",
    "    # Calculate the size of the validation set as 20% of the train set\n",
    "    # train_size = int(len(df) * 0.8)\n",
    "    # val_size = len(df) - train_size\n",
    "\n",
    "    # Create boolean masks for train, validation, and test\n",
    "    train_mask = (df['date'] >= train_start) & (df['date'] <= train_end)\n",
    "    # val_mask = (df['date'] > train_end) & (df['date'] <= test_end)\n",
    "    test_mask = (df['date'] > train_end) & (df['date'] <= test_end)\n",
    "\n",
    "    # Apply the masks to select the rows\n",
    "    train = df[train_mask]\n",
    "    #val = df[val_mask]\n",
    "    test = df[test_mask]\n",
    "\n",
    "    # Print the resulting train, validation, and test DataFrames\n",
    "    print(\"Train:\")\n",
    "    print(train)\n",
    "    # print(\"\\nValidation:\")\n",
    "    # print(val)\n",
    "    print(\"\\nTest:\")\n",
    "    print(test)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_val_test(df_w_node_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes in the test graph: \", len(graph_test.nodes), \" number of labels retrieved: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54313b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([graph_train.nodes[i]['fraud']  for i in graph_train.nodes])\n",
    "test_labels = np.array([graph_test.nodes[i]['fraud']  for i in graph_test.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e498e31-82ab-4f48-b57f-5fc0eef04af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([graph_train.nodes[i]['fraud']  for i in graph_train.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes in the train graph: \", len(graph_train.nodes), \" number of labels retrieved: \", len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1f09a-c4d2-477d-b9f3-ba711c016df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_train.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92c561-56b4-4641-94b4-bf57077e48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_test.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c47a8a7-c187-424a-a060-9534a8548029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CARD_PAN_ID', 'TERM_MIDUID', 'TERM_MCC', 'TX_AMOUNT', 'TX_ACCEPTED', 'TX_FRAUD']\n"
     ]
    }
   ],
   "source": [
    "attribute_cols = list(df.columns)\n",
    "print(attribute_cols)\n",
    "attribute_cols.remove('CARD_PAN_ID')\n",
    "# attribute_cols.remove('AGENT_NAME')\n",
    "attribute_cols.remove('TERM_MIDUID')\n",
    "attribute_cols.remove('TX_FRAUD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40cb91e1-6788-4be6-95b1-3ad370c9fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import circular_layout, spectral_layout\n",
    "\n",
    "def make_graph(df):\n",
    "    G = nx.Graph()\n",
    "    # nx.set_edge_attributes(G_to_draw, labels, \"labels\")\n",
    "    for index, row in df.iterrows():\n",
    "        set_node_attributes(G, row[attribute_cols].values, name=row['TERM_MIDUID'])\n",
    "        G.add_node(row['CARD_PAN_ID'],shape=\"square\", fraud=row['TX_FRAUD'])\n",
    "        G.add_node(row['TERM_MIDUID'], shape=\"circle\", fraud=0)\n",
    "        G.add_edge(row['CARD_PAN_ID'], row['TERM_MIDUID'])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ade680a-8d85-45c7-8f63-06a0f67d33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_train =  make_graph(df.head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55591590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def get_edge_index(graph):\n",
    "    # create edge index\n",
    "    adj = nx.to_scipy_sparse_array(graph).tocoo()\n",
    "    row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
    "    col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "    return edge_index\n",
    "\n",
    "def get_embeddings(graph):\n",
    "    # extracting network measures to use as node attributes\n",
    "    #degree=np.array(list(dict(graph.degree()).values())).reshape(-1,1) \n",
    "    degree_centrality=np.array(list(dict(nx.degree_centrality(graph)).values())).reshape(-1,1)\n",
    "    #closeness=np.array(list(dict(nx.closeness_centrality(graph)).values())).reshape(-1,1)\n",
    "    #betweenness=np.array(list(dict(nx.betweenness_centrality(graph)).values())).reshape(-1,1)\n",
    "    clustering_coefficient=np.array(list(dict(nx.clustering(graph)).values())).reshape(-1,1)\n",
    "    pagerank = np.array(list(dict(nx.pagerank(graph)).values())).reshape(-1,1)\n",
    "    #personalised_pagerank=np.array(list(dict(nx.pagerank(graph, personalization=nx.get_node_attributes(graph, 'fraud'))).values())).reshape(-1,1)\n",
    "    #embeddings = np.concatenate((degree, closeness, betweenness,distance_instructor, distance_admin),axis=1)\n",
    "   \n",
    "    #embeddings = np.concatenate((degree, closeness, betweenness),axis=1)\n",
    "    embeddings = np.concatenate((degree_centrality, clustering_coefficient, pagerank),axis=1)\n",
    "    # normalizing the attributes\n",
    "    scale = StandardScaler()\n",
    "    embeddings = scale.fit_transform(embeddings)#.reshape(-1,1))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2788458-3c4b-4a45-9fb3-535ee1675f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([graph_train.nodes[i]['fraud']  for i in graph_train.nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92901e69-eba9-4fcf-b366-4c5e89d2cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bac44fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 ms, sys: 3.17 ms, total: 16.7 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_index_train = get_edge_index(graph_train)\n",
    "#edge_index_test = get_edge_index(graph_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09489d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3685e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 ms, sys: 4.08 ms, total: 48.8 ms\n",
      "Wall time: 50 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_train = get_embeddings(graph_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e9683-8315-4e55-8839-614f129c92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29af50c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.82 s, sys: 19.4 ms, total: 7.84 s\n",
      "Wall time: 7.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#embeddings_test = get_embeddings(graph_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77209ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Data objects\n",
    "## Train\n",
    "data_train = Data(edge_index=edge_index_train)\n",
    "data_train.num_nodes = graph_train.number_of_nodes()\n",
    "# labels\n",
    "y_train = torch.from_numpy(train_labels).type(torch.long)\n",
    "data_train.y = y_train.clone().detach()\n",
    "data_train.num_classes = 2\n",
    "'''\n",
    "## Test\n",
    "data_test = Data(edge_index=edge_index_test)\n",
    "data_test.num_nodes = graph_test.number_of_nodes()\n",
    "# labels\n",
    "y_test = torch.from_numpy(test_labels).type(torch.long)\n",
    "data_test.y = y_test.clone().detach()\n",
    "data_test.num_classes = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f867ba6b-4ee0-4073-bfe0-8bd6ce18932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Data objects\n",
    "## Train\n",
    "data_train = Data(edge_index=edge_index_train)\n",
    "data_train.num_nodes = graph_train.number_of_nodes()\n",
    "# labels\n",
    "y_train = torch.from_numpy(train_labels).type(torch.long)\n",
    "data_train.y = y_train.clone().detach()\n",
    "data_train.num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7911e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding train\n",
    "data_train.x = torch.from_numpy(embeddings_train).type(torch.float32)\n",
    "# embedding test\n",
    "#data_test.x = torch.from_numpy(embeddings_test).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45a62b-04cc-44c1-887b-7b9fb655a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6cd15-6bee-4515-bb39-eb2ba6c4ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a9818",
   "metadata": {},
   "source": [
    "RUN UNTIL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6a28245-1734-45a3-89c4-02587e30bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd38c90-e099-4c5b-9a2b-52b036612a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.lof import LOF\n",
    "from torch_geometric.nn import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e552aff-935d-424f-bf7f-a6498a57a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.detector import SCAN\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "model = SCAN(eps=0.5, mu=2, contamination=0.1, verbose=0)\n",
    "model.fit(data_train)\n",
    "# get outlier scores on the training data (transductive setting)\n",
    "score = model.decision_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, score = model.predict(data_train, return_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181632f7-c6d9-48a8-9585-8f91fe9b21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = eval_roc_auc(data_train.y, score)\n",
    "\n",
    "print(\" * score \", score)\n",
    "print(\" * pred \", pred)\n",
    "print('AUC Score:', auc_score)\n",
    "\n",
    "from pygod.detector import DOMINANT\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "model = DOMINANT(hid_dim=64, num_layers=4, epoch=30, gpu=0)\n",
    "model.fit(data)\n",
    "# get outlier scores on the training data (transductive setting)\n",
    "score = model.decision_score_\n",
    "# predict labels and scores on the testing data (inductive setting)\n",
    "#pred, score = model.predict(data_test, return_score=True)\n",
    "#auc_score = eval_roc_auc(data_test.y, score)\n",
    "\n",
    "print(\" * score \", score)\n",
    "'''print(\" * pred \", pred)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059343c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.detector import DOMINANT\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "model = DOMINANT(hid_dim=64, num_layers=4, epoch=30, gpu=0)\n",
    "model.fit(data_train)\n",
    "# get outlier scores on the training data (transductive setting)\n",
    "score = model.decision_score_\n",
    "# predict labels and scores on the testing data (inductive setting)\n",
    "pred, score = model.predict(data_test, return_score=True)\n",
    "auc_score = eval_roc_auc(data_test.y, score)\n",
    "\n",
    "print(\" * score \", score)\n",
    "print(\" * pred \", pred)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8094d91e-257d-4df9-b74d-9d99ed87cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.detector import DOMINANT\n",
    "from pygod.metric import eval_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a9b71-af27-49d3-bbcf-375f7a4528a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd96d65-427d-467c-8731-9d84c3b662a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.detector import AdONE\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "model = AdONE(hid_dim=64, num_layers=4,epoch=100)\n",
    "model.fit(data_train)\n",
    "# get outlier scores on the training data (transductive setting)\n",
    "score = model.decision_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5312f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Model:  DOMINANT\n",
      "Model:  ANOMALOUS\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD A SHALLOW MODEL SUCH AS SCAN\n",
    "from pygod.detector import DOMINANT, ANOMALOUS, GAAN, AnomalyDAE, GAE, AdONE, SCAN\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "cuda = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "\n",
    "model_list = {}\n",
    "dominant_model = DOMINANT(hid_dim=64, num_layers=4, epoch=100, gpu=0)\n",
    "anomalous_model = ANOMALOUS(gamma=1.0, weight_decay=0.0, lr=0.004, epoch=100, gpu=0, contamination=0.1, verbose=0)\n",
    "gaan_model = GAAN(noise_dim=16, hid_dim=64, num_layers=4, contamination=0.1, lr=0.004, epoch=100, gpu=0)\n",
    "anomalydae_model = AnomalyDAE(emb_dim=64, hid_dim=64, num_layers=4,epoch=100, gpu=0)\n",
    "gae_model = GAE(hid_dim=64, num_layers=4, epoch=100)\n",
    "adone_model = AdONE(hid_dim=64, num_layers=4,epoch=100, gpu=0)\n",
    "scan_model = SCAN(eps=0.5, mu=2, contamination=0.1, verbose=0)\n",
    "\n",
    "model_list[\"DOMINANT\"] = dominant_model\n",
    "model_list[\"ANOMALOUS\"] = anomalous_model\n",
    "model_list[\"GAAN\"] = gaan_model\n",
    "model_list[\"AnomalyDAE\"] = anomalydae_model\n",
    "model_list[\"GAE\"] = gae_model\n",
    "model_list[\"AdONE\"] = adone_model\n",
    "model_list[\"SCAN\"] = scan_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: CHANGE THIS TO USE THE TEST SET\n",
    "for model_name, model in model_list.items():\n",
    "    print(\"Model: \", model_name)\n",
    "    model.fit(data)\n",
    "    # get outlier scores on the training data (transductive setting)\n",
    "    score = model.decision_score_\n",
    "    # predict labels and scores on the testing data (inductive setting)\n",
    "    #pred, score = model.predict(data_test, return_score=True)\n",
    "    # auc_score = eval_roc_auc(data_test.y, score)\n",
    "   \n",
    "    #print(\" * score \", score)\n",
    "    #print(\" * pred \", pred)\n",
    "    # print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1ef5a20c-2462-4cde-a808-54327d97e8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd3951-a2ac-4dec-933d-432fbdf0216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f98abf-73e0-40e2-879c-b5388427db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cuda.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4aed1fad-b0bb-4d2c-9df8-af455a4357e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y = data.y.bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "130e65c7-a4d2-42a4-a6e1-9bf4b235bd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 1774], num_nodes=1199, num_classes=2, x=[1199, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "223607d5-e0b0-49c3-ac39-d2e5b2028df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a dominant detector\n",
    "from pygod.detector import DOMINANT\n",
    "\n",
    "model = DOMINANT(num_layers=4, epoch=20)  # hyperparameters can be set here\n",
    "model.fit(data)  # input data is a PyG data object\n",
    "\n",
    "# get outlier scores on the training data (transductive setting)\n",
    "score = model.decision_score_\n",
    "\n",
    "# predict labels and scores on the testing data (inductive setting)\n",
    "#pred, score = model.predict(test_data, return_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91b706-5cf9-414f-a18a-72fb80912c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c74936c-c8f7-4926-b27a-6ca29b443412",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_train.y.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ca90ffc-ffb7-486c-9852-8aef02d20976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ff9c201-06a7-4b8a-b880-3336ccdaf90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([1.4246e-05, 1.4246e-05, 1.4246e-05,  ..., 1.4246e-05, 1.4246e-05,\n",
      "        8.8046e-03])\n",
      "Probability:\n",
      "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0185])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.3981171548117155\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import GAE\n",
    "\n",
    "detector = GAE(hid_dim=64, num_layers=4, epoch=100)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30529598-b01b-45a0-b778-623586378f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0.5005, 0.5005, 0.5005,  ..., 0.5005, 0.5005, 0.5058])\n",
      "Probability:\n",
      "tensor([0.0027, 0.0027, 0.0027,  ..., 0.0027, 0.0027, 0.0031])\n",
      "Confidence:\n",
      "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9537])\n",
      "AUC Score: 0.6502092050209205\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import DOMINANT\n",
    "\n",
    "detector = DOMINANT(hid_dim=64, num_layers=4, epoch=100, gpu=0)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b1e68ed-ce11-46e6-8b37-79974621ea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0.5023, 0.5023, 0.5023,  ..., 0.5023, 0.5023, 0.4993])\n",
      "Probability:\n",
      "tensor([0.0031, 0.0031, 0.0031,  ..., 0.0031, 0.0031, 0.0029])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.6523012552301255\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import DOMINANT\n",
    "\n",
    "detector = DOMINANT(hid_dim=256, dropout=0.1, num_layers=4, epoch=100, gpu=0)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd45e3b3-b9df-45b0-882f-49fa61bdcf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0.5070, 0.5070, 0.5070,  ..., 0.5070, 0.5070, 0.4984])\n",
      "Probability:\n",
      "tensor([0.0105, 0.0105, 0.0105,  ..., 0.0105, 0.0105, 0.0100])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.735878661087866\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import DOMINANT\n",
    "\n",
    "detector = DOMINANT(hid_dim=46, dropout=0.3, num_layers=4, epoch=1000, gpu=0)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6279a0e4-ed90-47bd-9a8b-ac385361c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidasa/bigdata/lib/python3.9/site-packages/pygod/detector/scan.py:162: UserWarning: This detector is transductive only. Training from scratch with the input data.\n",
      "  warnings.warn(\"This detector is transductive only. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Probability:\n",
      "tensor([nan, nan, nan,  ..., nan, nan, nan])\n",
      "Confidence:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "AUC Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import SCAN\n",
    "\n",
    "detector = SCAN(eps=0.5, mu=2, contamination=0.1, verbose=0)\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee72d9b8-200b-4a1e-97d0-907fe38b3407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidasa/bigdata/lib/python3.9/site-packages/pygod/detector/scan.py:162: UserWarning: This detector is transductive only. Training from scratch with the input data.\n",
      "  warnings.warn(\"This detector is transductive only. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Probability:\n",
      "tensor([nan, nan, nan,  ..., nan, nan, nan])\n",
      "Confidence:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "AUC Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import SCAN\n",
    "\n",
    "detector = SCAN(eps=0.8, mu=10, contamination=0.1, verbose=0)\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cda909-46ba-4084-8f8e-f172beb4271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.detector import GUIDE\n",
    "\n",
    "detector = GUIDE(hid_a=64, hid_s=4, num_layers=4, dropout=0.0, weight_decay=0.0, \n",
    "                    backbone=MLP, alpha=0.5, contamination=0.1, lr=0.004, epoch=epochs, gpu=0, \n",
    "                    batch_size=0, num_neigh=3, graphlet_size=4, selected_motif=True, cache_dir=None, \n",
    "                    verbose=0, save_emb=False, compile_model=False)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01645fc7-16ff-4e27-8698-171c8e809c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidasa/bigdata/lib/python3.9/site-packages/pygod/detector/gaan.py:124: UserWarning: MLP in GAAN does not use neighbor information.\n",
      "  warnings.warn('MLP in GAAN does not use neighbor information.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([1, 1, 1,  ..., 1, 1, 0])\n",
      "Raw scores:\n",
      "tensor([0.8325, 0.8325, 0.8325,  ..., 0.8325, 0.8325, 0.0000])\n",
      "Probability:\n",
      "tensor([0.4472, 0.4472, 0.4472,  ..., 0.4472, 0.4472, 0.0000])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.7370292887029288\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import GAAN\n",
    "\n",
    "detector = GAAN(noise_dim=8,\n",
    "                    hid_dim=32,\n",
    "                    weight_decay=0.01,\n",
    "                    dropout=0.1,\n",
    "                    lr=0.1,\n",
    "                    epoch=2,\n",
    "                    gpu=0,\n",
    "                    weight=0,\n",
    "                    batch_size=32,\n",
    "                    num_neigh=3)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8d36c0-0ac4-40a5-be23-7f402c67d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.detector import Radar\n",
    "\n",
    "detector = radar_model = Radar(gamma=1.0, weight_decay=0.01, lr=0.1, epoch=2, gpu=0, contamination=0.1, verbose=0)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b94921b2-dab6-4271-a753-a17ed22c0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidasa/bigdata/lib/python3.9/site-packages/pygod/detector/done.py:137: UserWarning: Backbone is not used in AdONE.\n",
      "  warnings.warn(\"Backbone is not used in AdONE.\")\n",
      "/home/aidasa/bigdata/lib/python3.9/site-packages/pygod/detector/done.py:217: UserWarning: This detector is transductive only. Training from scratch with the input data.\n",
      "  warnings.warn(\"This detector is transductive only. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0.0007, 0.0006, 0.0006,  ..., 0.0078, 0.0081, 0.0137])\n",
      "Probability:\n",
      "tensor([0.0008, 0.0004, 0.0004,  ..., 0.0280, 0.0294, 0.0506])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.3943514644351464\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import DONE\n",
    "\n",
    "detector =  DONE(hid_dim=64, num_layers=4, dropout=0.1, \n",
    "                  weight_decay=0.01, backbone=MLP, w1=0.2, w2=0.2, w3=0.2, w4=0.2, w5=0.2, \n",
    "                  contamination=0.1, lr=0.004, epoch=2, gpu=0, batch_size=64, num_neigh=3, verbose=0, save_emb=False, compile_model=False)\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85799c-5dde-469c-a633-0a6c1dfc1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.detector import ANOMALOUS\n",
    "\n",
    "detector = ANOMALOUS(gamma=1.0, weight_decay=0.0, lr=0.004, epoch=2, gpu=0, contamination=0.1, verbose=0)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4943f710-53c7-4679-a99e-18707ccda7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 1])\n",
      "Raw scores:\n",
      "tensor([ 7.5695,  7.5695,  7.5695,  ...,  7.5695,  7.5695, 11.5881])\n",
      "Probability:\n",
      "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2742])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.27918410041841\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import AnomalyDAE\n",
    "\n",
    "detector = AnomalyDAE(emb_dim=64, hid_dim=64, num_layers=4,epoch=100, gpu=0)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fc6efe8-9a5f-4e8f-acdd-2484b33d99ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([4.1430, 4.1430, 4.1430,  ..., 4.3615, 4.3615, 4.4246])\n",
      "Probability:\n",
      "tensor([0.0161, 0.0161, 0.0161,  ..., 0.0596, 0.0596, 0.0722])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.4044979079497908\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import AnomalyDAE\n",
    "\n",
    "detector = AnomalyDAE(emb_dim=64, hid_dim=64,batch_size = 64, lr=0.004, alpha=0.8, num_layers=4,epoch=5, gpu=0, num_neigh=3)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28b2682d-84cb-4bb2-99e3-13c74c16d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0.4964, 0.4964, 0.4964,  ..., 0.4946, 0.4946, 0.5041])\n",
      "Probability:\n",
      "tensor([0.0017, 0.0017, 0.0017,  ..., 0.0015, 0.0015, 0.0022])\n",
      "Confidence:\n",
      "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8732])\n",
      "AUC Score: 0.6771966527196652\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import CONAD\n",
    "\n",
    "detector = CONAD(emb_dim=64, hid_dim=64,batch_size = 64, lr=0.004, alpha=0.8, num_layers=4,epoch=5, gpu=0, num_neigh=3)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "932917e5-35c7-4f6d-9f27-3388df743fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0.5008, 0.5008, 0.5008,  ..., 0.4990, 0.4990, 0.4941])\n",
      "Probability:\n",
      "tensor([0.0026, 0.0026, 0.0026,  ..., 0.0025, 0.0025, 0.0022])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.8297071129707113\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import CONAD\n",
    "\n",
    "detector = CONAD(emb_dim=64, hid_dim=256,batch_size = 64, lr=0.004, alpha=0.8, num_layers=4,epoch=5, gpu=0, num_neigh=3)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49e243ce-3e6d-4658-aa8c-b83a7ed6b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0.5001, 0.5001, 0.5001,  ..., 0.4994, 0.4994, 0.4983])\n",
      "Probability:\n",
      "tensor([0.0027, 0.0027, 0.0027,  ..., 0.0026, 0.0026, 0.0025])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.6688284518828452\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import CONAD\n",
    "\n",
    "detector = CONAD(emb_dim=64, hid_dim=256,batch_size = 64, lr=0.01, alpha=0.8, num_layers=4,epoch=5, gpu=0, num_neigh=3)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba546dd7-7000-4604-8596-1ea8b5284c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidasa/bigdata/lib/python3.9/site-packages/pygod/detector/gaan.py:124: UserWarning: MLP in GAAN does not use neighbor information.\n",
      "  warnings.warn('MLP in GAAN does not use neighbor information.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Raw scores:\n",
      "tensor([0.8247, 0.8247, 0.8247,  ..., 0.8247, 0.8247, 0.0000])\n",
      "Probability:\n",
      "tensor([0.4454, 0.4454, 0.4454,  ..., 0.4454, 0.4454, 0.0000])\n",
      "Confidence:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "AUC Score: 0.8023012552301255\n"
     ]
    }
   ],
   "source": [
    "from pygod.detector import GAAN\n",
    "\n",
    "detector = GAAN(noise_dim=8,\n",
    "                    hid_dim=256,\n",
    "                    weight_decay=0.01,\n",
    "                    dropout=0.1,\n",
    "                    lr=0.1,\n",
    "                    epoch=2,\n",
    "                    gpu=0,\n",
    "                    weight=0,\n",
    "                    batch_size=64,\n",
    "                    num_neigh=3)\n",
    "\n",
    "#######################################################################\n",
    "# Training\n",
    "# --------\n",
    "# To train the detector with the loaded data, simply feed the\n",
    "# ``torch_geometric.data.Data`` object into the detector via ``fit``.\n",
    "\n",
    "\n",
    "detector.fit(data_train)\n",
    "\n",
    "#######################################################################\n",
    "# Inference\n",
    "# ---------\n",
    "# After training, the detector is ready to use. You can use the detector\n",
    "# to predict the labels, raw outlier scores, probability of the\n",
    "# outlierness, and prediction confidence. Here, we use the loaded data\n",
    "# as an example.\n",
    "\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data_train,\n",
    "                                           return_pred=True,\n",
    "                                           return_score=True,\n",
    "                                           return_prob=True,\n",
    "                                           return_conf=True)\n",
    "print('Labels:')\n",
    "print(pred)\n",
    "\n",
    "print('Raw scores:')\n",
    "print(score)\n",
    "\n",
    "print('Probability:')\n",
    "print(prob)\n",
    "\n",
    "print('Confidence:')\n",
    "print(conf)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluation\n",
    "# ----------\n",
    "# To evaluate the performance outlier detector with AUC score, you can:\n",
    "\n",
    "\n",
    "from pygod.metric import eval_roc_auc\n",
    "\n",
    "auc_score = eval_roc_auc(data_train.y.bool(), score)\n",
    "print('AUC Score:', auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d399c27ef7ec5815d95b5e2eb3b05ea0d5800532ae84cf38dc1e28286a9a747"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
